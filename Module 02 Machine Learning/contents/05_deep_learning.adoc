= Deep Learning

* 인공 신경망 알고리즘을 사용하는 머신 러닝
** 전통적인 머신 러닝은 하나 혹은 두 개의 계산 계층이 있는 간단한 신경망을 사용
** 딥 러닝 모델은 3개 이상의 계층을 사용하여 모델을 학습
* 비지도 학습을 통해 비정형 원시 데이터에서 정확한 출력을 만들기위한 특성, 특징 및 관계를 추출
* 정밀도를 높이기 위해 출력을 평가하고 개선

---

인공신경망(ANN)은 생물학적 두뇌의 뉴런을 기반으로 모델링된 네트워크입니다. 인공뉴런은 노드라고 하며, 여러 레이어로 클러스터화 되고 병렬로 작동합니다. 인공뉴런은 숫자로 된 신호를 수신하면 이를 처리하고 해당 뉴런과 연결된 다른 뉴런에 신호를 보냅니다. 사람의 뇌와 마찬가지로, 신경 강화를 통해 패턴 인식, 전문지식, 전반적인 학습을 개선합니다.

== 딥 러닝 동작 방식

신경망 또는 인공 신경망은 데이터 입력, 가중치 및 편향의 조합을 통해 인간의 뇌를 모방하려고 시도하며, 모두 실리콘 뉴런 역할을 합니다. 이러한 요소는 함께 작동하여 데이터 내의 개체를 정확하게 인식, 분류 및 설명합니다.

심층 신경망은 상호 연결된 여러 계층의 노드로 구성되며, 각 계층은 예측 또는 분류를 구체화하고 최적화하기 위해 이전 계층을 기반으로 합니다. 네트워크를 통한 이러한 계산 진행을 순전파(forward propagation)라고 합니다. 심층 신경망의 입력 및 출력 계층을 가시 계층이라고 합니다. 입력 계층은 딥 러닝 모델이 처리를 위해 데이터를 수집하는 곳이고, 출력 계층은 최종 예측 또는 분류가 이루어지는 곳입니다.

역전파(backpropagation)라고 불리는 또 다른 프로세스 경사 하강법과 같은 알고리즘을 사용하여 예측 오류를 계산한 다음 모델을 학습습하기 위해 레이어를 뒤로 이동하여 함수의 가중치와 편향을 조정합니다. 순전파(forward propagation)와 역전파(backpropagation)를 함께 사용하면 신경망이 예측을 수행하고 오류를 수정할 수 있습니다. 시간이 지남에 따라 알고리즘은 점점 더 정확해집니다.

딥 러닝에는 엄청난 양의 컴퓨팅 성능이 필요합니다. 고성능 그래픽 처리 장치(GPU)는 사용 가능한 메모리가 많은 다중 코어에서 대량의 계산을 처리할 수 있기 때문에 이상적입니다. 분산 클라우드 컴퓨팅도 도움이 될 수 있습니다. 이 수준의 컴퓨팅 성능은 딥 러닝을 통해 딥 알고리즘을 학습습하는 데 필요합니다. 그러나 온프레미스에서 여러 GPU를 관리하면 내부 리소스에 대한 수요가 많고 확장 비용이 엄청나게 많이 들 수 있습니다. 소프트웨어 요구 사항의 경우 대부분의 딥 러닝 앱은 JAX, PyTorch 또는 TensorFlow의 세 가지 학습 프레임워크 중 하나로 코딩됩니다.

== 딥 러닝 모델의 유형

딥 러닝 알고리즘은 매우 복잡하며 특정 문제나 데이터 세트를 해결하기 위한 다양한 유형의 신경망이 있습니다. 다음은 6가지입니다. 각각은 고유한 장점을 가지고 있으며 여기에 대략적으로 개발 순서대로 제시되어 있으며 각 연속 모델은 이전 모델의 약점을 극복하기 위해 조정됩니다.

모든 딥러닝 모델의 잠재적 약점 중 하나는 딥러닝 모델이 '블랙박스'인 경우가 많아 내부 작동 방식을 이해하기 어렵고 해석하기 어렵다는 점입니다. 그러나 이는 높은 정확도 및 확장성의 전반적인 이점과 균형을 이룰 수 있습니다.

=== CNN

컨벌루션 신경망(CNN 또는 ConvNet)은 주로 컴퓨팅 비전 및 이미지 분류 애플리케이션에 사용됩니다. 이미지와 비디오 내의 특징과 패턴을 감지하여 물체 감지, 이미지 인식, 패턴 인식 및 얼굴 인식과 같은 작업을 수행할 수 있습니다. 이러한 신경망은 선형 대수학, 특히 행렬 곱셈의 원리를 활용하여 이미지 내의 패턴을 식별합니다.

CNN은 입력 레이어, 하나 이상의 숨겨진 레이어 및 출력 레이어를 포함하는 노드 레이어로 구성된 특정 유형의 신경망입니다. 각 노드는 서로 연결되어 있으며 연계된 가중치와 임계값을 가집니다. 개별 노드의 아웃풋이 지정된 임곗값을 초과하면 해당 노드가 활성화되어 네트워크의 다음 계층으로 데이터를 보냅니다. 그렇지 않으면 데이터는 네트워크의 다음 계층으로 전달되지 않습니다.

CNN을 구성하는 계층의 세 가지 주요 유형, 즉 컨볼루션 계층, 풀링 계층 및 완전 연결(FC) 계층이 있습니다. 복잡한 용도의 경우 CNN에는 최대 수천 개의 레이어가 포함될 수 있으며 각 레이어는 이전 레이어를 기반으로 합니다. 원래 입력을 작업하고 재작업하는 "컨볼루션"을 통해 자세한 패턴을 발견할 수 있습니다. 각 계층에서 CNN은 복잡성이 증가하여 이미지의 더 많은 부분을 식별합니다. 이전 계층은 색상 및 가장자리와 같은 간단한 기능에 중점을 둡니다. 이미지 데이터가 CNN의 계층을 따라 진행됨에 따라 최종적으로 의도된 오브젝트를 식별할 때까지 개체의 오브젝트 큰 요소 또는 모양을 인식하기 시작합니다.

CNN은 이미지, 음성 또는 오디오 신호 입력에서 우수한 성능으로 다른 신경망과 구별됩니다. CNN 이전에는 이미지에서 물체를 식별하기 위해 시간이 많이 소요되는 수동 특징 추출 방법이 사용되었습니다. 그러나 이제 CNN은 이미지 분류 및 객체 인식 작업에 대한 보다 확장 가능한 접근 방식을 제공하고 고차원 데이터를 처리합니다. 또한 CNN은 계층 간에 데이터를 교환하여 보다 효율적인 데이터 처리를 제공할 수 있습니다. 풀링 계층에서 정보가 손실될 수 있지만, 복잡성을 줄이고 효율성을 개선하며 과적합 위험을 제한하는 데 도움이 될 수 있는 CNN의 이점보다 더 중요할 수 있습니다. 

CNN에는 시간과 예산이 많이 필요하고 많은 그래픽 처리 장치(GPU)가 필요하기 때문에 계산이 까다롭다는 단점도 있습니다. 또한 도메인 간 지식을 갖춘 고도로 훈련된 전문가와 구성, 하이퍼파라미터 및 구성에 대한 신중한 테스트가 필요합니다.

=== RNN

순환 신경망(RNN) 순차 또는 시계열 데이터를 사용하기 때문에 일반적으로 자연어 및 음성 인식 애플리케이션에 사용됩니다. RNN은 피드백 루프로 식별할 수 있습니다. 이러한 학습 알고리즘은 주로 시계열 데이터를 사용하여 미래 결과를 예측할 때 사용됩니다. 사용 사례에는 주식 시장 예측이나 판매 예측, 언어 번역, 자연어 처리(NLP), 음성 인식 및 이미지 캡션과 같은 순서적 또는 시간적 문제가 포함됩니다. 이러한 기능은 종종 Siri, 음성 검색 및 Google 번역과 같은 인기 있는 응용 프로그램에 통합됩니다.

RNN은 이전 입력에서 정보를 가져와 현재 입력과 출력에 영향을 줄 때 '메모리'를 사용합니다. 기존의 심층 신경망은 입력과 출력이 서로 독립적이라고 가정하지만, RNN의 출력은 시퀀스 내의 이전 요소에 따라 달라집니다. 미래의 이벤트도 주어진 시퀀스의 출력을 결정하는 데 도움이 되지만, 단방향 반복 신경망은 예측에서 이러한 이벤트를 설명할 수 없습니다.

RNN은 신경망의 각 계층에서 파라미터를 공유하고, 네트워크의 각 계층 내에서 동일한 가중치 파라미터를 공유하며, 강화 학습을 용이하게 하기 위해 역전파 및 경사하강법 과정을 통해 가중치를 조정합니다.

RNN은 BPTT(backpropagation through time) 알고리즘을 사용하여 그래디언트를 결정하는데, 이는 시퀀스 데이터에 따라 다르기 때문에 기존의 역전파와 약간 다릅니다. BPTT의 원리는 모델이 출력 계층에서 입력 계층으로 오류를 계산하여 스스로 학습하는 기존의 역전파와 동일합니다. BPTT는 각 시간 스텝에서 오차의 합을 구하는 반면, 피드포워드 신경망은 각 계층에서 파라미터를 공유하지 않기 때문에 오차의 합을 구할 필요가 없다는 점에서 기존 접근 방식과 다릅니다.

다른 신경망 유형에 비해 RNN이 이진 데이터 처리와 메모리를 모두 사용한다는 장점이 있습니다. RNN은 단일 입력에 대해 하나의 결과만 제공하는 대신 RMM이 일대다, 다대일 또는 다대다 출력을 생성할 수 있도록 여러 입력 및 프로덕션을 계획할 수 있습니다.

RNN에도 옵션이 있습니다. 예를 들어, 장단기 기억(LSTM) 신경망은 장기 종속성을 학습하고 이에 따라 작동하므로 단순 RNN보다 우수합니다.

그러나 RNN은 그래디언트 폭발 및 소실 그래디언트로 알려진 두 가지 기본 문제에 부딪히는 경향이 있습니다. 이러한 문제는 기울기의 크기로 정의되며, 이는 오차 곡선을 따른 손실 함수의 기울기입니다.

그래디언트가 사라지고 너무 작으면 가중치 매개변수가 중요하지 않게 될 때까지(즉, 영(0)) 업데이트하면서 계속 작아집니다. 이러한 상황이 발생하면 알고리즘은 더 이상 학습하지 않습니다.
그라디언트 폭발: 이 문제는 그라데이션이 너무 커서 불안정한 모델을 만들 때 발생합니다. 이 경우 모델 가중치가 너무 커져서 결국 NaN(숫자가 아님)으로 표시됩니다. 이러한 문제에 대한 한 가지 해결책은 신경망 내의 은닉 레이어 수를 줄여 RNN 모델의 복잡성을 제거하는 것입니다.
몇 가지 마지막 단점: RNN은 긴 학습 시간이 필요하고 대규모 데이터 세트에서 사용하기 어려울 수도 있습니다. 레이어와 파라미터가 많은 경우 RNN을 최적화하면 복잡성이 가중됩니다.

=== 오토인코더 및 변형 오토인코더

딥 러닝은 이미지, 음성 및 기타 복잡한 데이터 유형의 분석을 추가하여 수치 데이터 분석을 넘어서는 것을 가능하게 했습니다. 이를 달성하기 위한 첫 번째 클래스의 모델 중에는 VAE(Variation Autoencoders)가 있습니다. 이는 사실적인 이미지와 음성을 생성하는 데 널리 사용된 최초의 딥 러닝 모델로서, 모델을 더 쉽게 확장하여 딥 제너레이티브 모델링의 역량을 강화했습니다. 이는 우리가 생각하는 생성형 AI의 초석입니다.

자동 인코더는 레이블이 없는 데이터를 압축된 표현으로 인코딩한 다음 데이터를 원래 형식으로 다시 디코딩하는 방식으로 작동합니다. 일반 자동 인코더는 손상되거나 흐릿한 이미지를 재구성하는 등 다양한 용도로 사용되었습니다. 변형 자동 인코더는 데이터를 재구성할 뿐만 아니라 원본 데이터의 변형을 출력할 수 있는 중요한 기능을 추가했습니다.

새로운 데이터를 생성하는 이러한 능력은 생성적 대립 신경망(GAN)에서 확산 모델에 이르기까지 더욱 현실적이면서도 가짜인 이미지를 생성할 수 있는 새로운 기술의 연속적인 급속한 발전을 촉발시켰습니다. 이러한 방식으로 VAE는 오늘날의 생성형 AI를 위한 기반을 마련했습니다.

오토인코더는 인코더와 디코더 블록으로 구축되며, 이 아키텍처는 오늘날의 대규모 언어 모델도 뒷받침합니다. 인코더는 데이터 세트를 조밀한 표현으로 압축하여 유사한 데이터 요소를 추상 공간에 더 가깝게 정렬합니다. 디코더는 이 공간에서 샘플링하여 데이터 세트의 가장 중요한 기능을 유지하면서 새로운 것을 만듭니다.

오토인코더의 가장 큰 장점은 대량의 데이터 배치를 처리하고 입력 데이터를 압축된 형식으로 표시할 수 있다는 점으로, 가장 중요한 측면이 두드러져 이상 징후 감지 및 분류 작업을 수행할 수 있습니다. 또한 전송 속도가 빨라지고 스토리지 요구 사항이 줄어듭니다. 오토인코더는 레이블이 지정되지 않은 데이터에 대해 학습될 수 있으므로 레이블이 지정된 데이터를 사용할 수 없는 경우에 사용할 수 있습니다. 비지도 학습습을 사용하면 딥러닝 알고리즘이 수동 기능 엔지니어링 없이 자동으로 학습하고 정확도를 얻는 등 시간을 절약할 수 있는 이점이 있습니다. 또한 VAE는 텍스트 또는 이미지 생성을 위한 새로운 샘플 데이터를 생성할 수 있습니다.

오토인코더에는 단점이 있습니다. 깊거나 복잡한 구조를 학습하면 계산 리소스가 소모될 수 있습니다. 그리고 비지도 학습 중에 모델은 필요한 속성을 간과하고 대신 입력 데이터를 복제할 수 있습니다. 오토인코더는 구조화된 데이터의 복잡한 데이터 연결을 간과하여 복잡한 관계를 올바르게 식별하지 못할 수도 있습니다.

=== GAN

생성적 대립 신경망(GAN)은 인공 지능(AI) 내부와 외부 모두에서 원본 학습습 데이터와 유사한 새로운 데이터를 생성하는 데 사용되는 신경망입니다. 여기에는 사람의 얼굴로 보이는 이미지가 포함될 수 있지만 실제 사람을 촬영한 것이 아니라 생성된 이미지입니다. 이름의 '적대적'이라는 부분은 GAN의 두 부분, 즉 생성자와 판별자 사이의 앞뒤를 오가는 데서 유래했습니다.

생성기는 이미지, 비디오 또는 오디오와 같은 것을 생성한 다음 트위스트와 함께 출력을 생성합니다. 예를 들어, 말은 어느 정도의 정확도로 얼룩말로 변형될 수 있습니다. 결과는 입력과 이 사용 사례의 생성 모델에서 레이어가 얼마나 잘 학습습되었는지에 따라 달라집니다.
판별자는 생성적 결과(가짜 이미지)를 데이터 세트의 실제 이미지와 비교하는 적대자입니다. 판별자는 진짜와 가짜 이미지, 비디오 또는 오디오를 구별하려고 합니다.
GAN은 스스로 학습습합니다. 생성기는 가짜를 생성하고 판별기는 생성기의 가짜와 실제 예제 간의 차이점을 찾는 방법을 학습합니다. 판별자가 가짜를 식별할 수 있으면 생성자는 처벌을 받습니다. 피드백 루프는 생성기가 판별자가 구별할 수 없는 출력을 생성하는 데 성공할 때까지 계속됩니다.

GAN의 주요 이점은 원본과 구별하기 어려울 수 있는 사실적인 출력을 생성하는 것이며, 이는 기계 학습 모델을 추가로 학습하는 데 사용될 수 있습니다. 학습할 GAN을 설정하는 것은 레이블이 지정되지 않은 데이터 또는 사소한 레이블 지정을 사용하여 학습되기 때문에 간단합니다. 그러나 잠재적인 단점은 생성기와 판별기가 오랫동안 경쟁에서 앞뒤로 이동하여 큰 시스템 드레인을 생성할 수 있다는 것입니다. 한 가지 학습 제한 사항은 만족스러운 출력을 얻기 위해 엄청난 양의 입력 데이터가 필요할 수 있다는 것입니다. 또 다른 잠재적인 문제는 생성기가 더 넓은 다양성이 아닌 제한된 출력 세트를 생성하는 "모드 붕괴"입니다.

=== 확산 모델

확산 모델은 점진적인 노이즈 추가 및 제거의 순방향 및 역방향 확산 프로세스를 사용하여 학습되는 생성 모델입니다. 확산 모델은 학습된 데이터와 유사한 데이터(대부분 이미지)를 생성한 다음 학습에 사용된 데이터를 덮어씁니다. 학습 데이터에 가우시안 노이즈를 인식할 수 없을 때까지 점차적으로 추가한 다음, 무작위 노이즈 입력에서 출력(일반적으로 이미지)을 합성할 수 있는 역방향 '노이즈 제거' 프로세스를 학습합니다.

확산 모델은 생성된 샘플과 원하는 대상의 차이를 최소화하는 방법을 학습합니다. 모든 불일치가 정량화되고 모델의 매개변수가 업데이트되어 손실을 최소화하여 실제 학습 데이터와 매우 유사한 샘플을 생성하도록 모델을 학습합니다.

이미지 품질 외에도 확산 모델은 적대적 교육이 필요하지 않아 학습 프로세스를 가속화하고 긴밀한 프로세스 제어를 제공한다는 장점이 있습니다. 학습습은 GAN보다 더 안정적이며 확산 모델은 모드 붕괴가 발생하기 쉽지 않습니다.

그러나 GAN에 비해 확산 모델은 더 많은 미세 조정을 포함하여 학습습하는 데 더 많은 컴퓨팅 리소스가 필요할 수 있습니다. 또한 IBM Research® 는 이러한 형태의 생성형 AI가 숨겨진 백도어로 하이재킹될 수 있다는 사실을 발견했습니다. 이를 통해 공격자는 이미지 생성 프로세스를 제어할 수 있으므로 AI 확산 모델을 속여 조작된 이미지를 생성할 수 있습니다.

=== 변환기 모델

변환기 모델은 인코더-디코더 아키텍처와 텍스트 처리 메커니즘을 결합하여 언어 모델 학습 방식에 혁명을 일으켰습니다. 인코더는 주석이 없는 원시 텍스트를 임베딩으로 알려진 표현으로 변환합니다. 디코더는 이러한 임베딩을 모델의 이전 출력과 함께 가져와서 문장의 각 단어를 연속적으로 예측합니다.

엔코더는 빈칸 채우기 추측을 사용하여 단어와 문장이 서로 어떻게 관련되어 있는지 학습하여 품사 및 기타 문법적 특징에 레이블을 지정할 필요 없이 강력한 언어 표현을 구축합니다. 실제로 트랜스포머는 특정 작업을 염두에 두지 않고 처음부터 사전 학습습할 수 있습니다. 이러한 강력한 표현을 학습한 후에는 나중에 훨씬 적은 데이터로 모델을 특수화하여 요청된 작업을 수행할 수 있습니다.

몇 가지 혁신이 이를 가능하게 합니다. 트랜스포머는 문장의 단어를 동시에 처리하여 텍스트 처리를 병렬로 가능하게 하여 학습 속도를 높입니다. 순환 신경망(RNN)을 포함한 초기 기술은 단어를 하나씩 처리했습니다. 트랜스포머는 또한 단어의 위치와 그 관계를 학습했는데, 이 문맥을 통해 의미를 추론하고 긴 문장에서 "그것"과 같은 단어를 모호하게 할 수 있습니다.

트랜스포머는 작업을 미리 정의할 필요가 없어 방대한 양의 원시 텍스트에 대해 언어 모델을 사전 학습하는 것을 실용적으로 만들어 크기를 크게 늘릴 수 있었습니다. 이전에는 특정 작업에 대해 하나의 모델을 학습습하기 위해 레이블이 지정된 데이터를 수집했습니다. 트랜스포머를 사용하면 방대한 양의 데이터에 대해 학습된 하나의 모델을 레이블이 지정된 소량의 작업별 데이터에서 미세 조정하여 여러 작업에 맞게 조정할 수 있습니다.

오늘날 언어 트랜스포머는 분류 및 엔터티 추출과 같은 비생성적 작업뿐만 아니라 기계 번역, 요약 및 질의응답을 포함한 생성적 작업에도 사용됩니다. 트랜스포머는 설득력 있는 대화, 에세이 및 기타 콘텐츠를 생성하는 능력으로 많은 사람들을 놀라게 했습니다.

자연어 처리 (NLP) 변환기는 병렬로 실행되어 시퀀스의 여러 부분을 동시에 처리할 수 있어 학습 속도를 크게 높일 수 있기 때문에 놀라운 성능을 제공합니다. 트랜스포머는 또한 텍스트의 장기 종속성을 추적하므로 전체 컨텍스트를 더 명확하게 이해하고 우수한 결과를 얻을 수 있습니다. 또한 트랜스포머는 확장성과 유연성이 뛰어나 작업별로 맞춤화할 수 있습니다.

트랜스포머는 그 복잡성 때문에 막대한 컴퓨팅 리소스와 긴 교육 시간이 필요하다는 한계가 있습니다. 또한 정확한 결과를 도출하려면 학습 데이터가 정확하게 타겟에 맞고 편향되지 않으며 풍부해야 합니다.

== 딥 러닝 사용 사례

딥 러닝의 활용 사례는 매일 증가하고 있습니다. 다음은 기업이 보다 효율적이고 고객에게 더 나은 서비스를 제공하는 데 도움이 되는 몇 가지 방법입니다.

=== 애플리케이션 현대화

생성형 AI는 개발자의 역량을 강화하고 애플리케이션 현대화 및 IT 자동화 영역에서 점점 더 커지는 기술 격차를 줄일 수 있습니다. 코딩을 위한 생성형 AI는 최근 대규모 언어 모델(LLM) 기술과 NLP(자연어 처리) 기술의 획기적인 발전으로 인해 가능합니다. 딥 러닝 알고리즘과 기존 소스 코드의 방대한 데이터 세트에서 학습습된 대규모 신경망을 사용합니다. 학습 코드는 일반적으로 오픈 소스 프로젝트에서 생성된 공개적으로 사용 가능한 코드에서 제공됩니다.

프로그래머는 코드에서 수행하려는 작업을 설명하는 일반 텍스트 프롬프트를 입력할 수 있습니다. 생성형 AI 도구는 코드 스니펫 또는 전체 기능을 제안하여 반복적인 작업을 처리하고 수동 코딩을 줄여 코딩 프로세스를 간소화합니다. 또한 생성형 AI는 코드를 한 언어에서 다른 언어로 번역하여 코드 변환 또는 현대화 프로젝트(예: COBOL을 Java로 변환하여 레거시 애플리케이션 업데이트)를 간소화할 수 있습니다.

=== 컴퓨팅 비전

컴퓨팅 비전은 이미지 분류, 객체 감지, 의미론적 분할을 포함하는 인공지능(AI) 분야입니다. 머신 러닝과 신경망을 사용하여 컴퓨터와 학습 시스템이 디지털 이미지, 비디오 및 기타 시각적 입력에서 의미 있는 정보를 도출하고 시스템이 결함이나 문제를 발견하면 권장 사항을 제시하거나 조치를 취하도록 학습합니다. AI가 컴퓨터가 생각할 수 있게 해준다면, 컴퓨팅 비전은 컴퓨터가 보고, 관찰하고, 이해할 수 있게 해줍니다.

컴퓨팅 비전 시스템은 종종 제품을 검사하거나 생산 자산을 감시하도록 학습습되기 때문에 일반적으로 분당 수천 개의 제품 또는 프로세스를 분석하여 눈에 띄지 않는 결함이나 문제를 알아차릴 수 있습니다. 컴퓨팅 비전은 에너지 및 유틸리티에서 제조 및 자동차에 이르기까지 다양한 산업에서 사용됩니다.

컴퓨팅 비전에는 많은 데이터가 필요하며, 이미지를 식별하고 궁극적으로 인식할 때까지 해당 데이터에 대한 분석을 반복해서 실행합니다. 예를 들어, 자동차 타이어를 인식하도록 컴퓨터를 학습습시키려면 방대한 양의 타이어 이미지와 타이어 관련 항목을 제공하여 차이점을 학습하고 타이어, 특히 결함이 없는 타이어를 인식해야 합니다.

컴퓨팅 비전은 알고리즘 모델을 사용하여 컴퓨터가 시각적 데이터의 컨텍스트에 대해 스스로 학습할 수 있도록 합니다. 모델을 통해 충분한 데이터가 공급되면 컴퓨터는 데이터를 "보고" 한 이미지를 다른 이미지와 구별하도록 스스로 학습합니다. 알고리즘을 사용하면 누군가가 이미지를 인식하도록 프로그래밍하는 대신 기계가 스스로 학습할 수 있습니다.

컴퓨팅 비전을 통해 시스템은 디지털 이미지, 비디오 및 기타 시각적 입력에서 의미 있는 정보를 도출하고 이러한 입력을 기반으로 조치를 취할 수 있습니다. 추천을 제공하는 이 기능은 이미지 인식 작업과 구별됩니다. 오늘날 이 컴퓨팅 비전의 몇 가지 일반적인 응용 분야는 다음에서 볼 수 있습니다.

* 자동차: 아직 무인 자동차 시대가 도래하지는 않았지만, 차선 감지 등의 기능을 통해 운전자와 승객의 안전을 개선하는 기반 기술이 자동차에 적용되기 시작했습니다.
* 의료: 컴퓨팅 비전이 방사선 기술에 통합되어 의사가 건강한 해부학적 구조에서 암 종양을 더 잘 식별할 수 있습니다.
* 마케팅: 소셜 미디어 플랫폼에서 프로필에 게시된 사진 속 인물 추천 기능을 제공하여 사진 앨범에서 친구를 쉽게 태그할 수 있도록 해 줍니다.
* 소매업: 일부 전자 상거래 플랫폼에는 시각적 검색 기능이 통합되어 브랜드가 기존 옷장에 어울리는 아이템을 추천할 수 있습니다.

=== 고객 상담

AI는 기업이 증가하는 소비자 요구를 더 잘 이해하고 충족할 수 있도록 돕고 있습니다. 고도로 개인화된 온라인 쇼핑, 소비자 직접 판매 모델, 배달 서비스가 증가함에 따라 생성형 AI는 고객 관리, 인재 혁신, 애플리케이션 성능을 개선할 수 있는 다양한 이점을 실현하는 데 도움이 될 수 있습니다.

AI는 기업이 고객 피드백과 구매 습관에서 얻은 귀중한 인사이트를 활용하여 고객 중심 접근 방식을 채택할 수 있도록 지원합니다. 이러한 데이터 기반 접근 방식은 제품 설계 및 포장을 개선하는 데 도움이 될 수 있으며 높은 고객 만족도와 매출 증대를 촉진하는 데 도움이 될 수 있습니다.

또한 생성형 AI는 대화 기록, 감정 분석 및 콜센터 기록에 기반하여 상황에 맞는 안내를 제공하는 고객 관리용 인지 도우미 역할도 수행할 수 있습니다. 또한, 생성형 AI는 개인화된 쇼핑 경험을 제공하고 고객 충성도를 높이며 경쟁 우위를 제공할 수 있습니다.

=== 디지털 인력

조직은 로보틱 프로세스 자동화(RPA) 및 디지털 노동을 구축 및 배포하여 사람과 협업하여 생산성을 높이거나 백업이 필요할 때마다 지원함으로써 인력을 보강할 수 있습니다. 예를 들어, 개발자가 레거시 소프트웨어의 업데이트 속도를 높이는 데 도움이 될 수 있습니다.

디지털 노동은 파운데이션 모델을 사용하여 기술적 장벽 없이 빠르고 안정적인 방식으로 셀프 서비스 자동화를 지원함으로써 지식 근로자의 생산성을 자동화하고 개선합니다. 태스크 성능 또는 API 호출을 자동화하기 위해 엔터프라이즈급 LLM 기반 슬롯 채우기 모델은 대화에서 정보를 식별하고 많은 수동 작업 없이 작업을 완료하거나 API를 호출하는 데 필요한 모든 정보를 수집할 수 있습니다.

기술 전문가가 지식 근로자를 위해 반복적인 작업 흐름을 기록하고 인코딩하는 대신, 지식 근로자는 모델 기반 대화형 지침 및 데모를 기반으로 구축된 디지털 노동 자동화를 셀프 서비스 자동화에 사용할 수 있습니다. 예를 들어 코드 작성 속도를 높이기 위해 노코드 디지털 견습생은 코드를 효과적으로 교육, 감독 및 검증하여 프로그래밍 전문 지식이 부족한 최종 사용자를 도울 수 있습니다. 

=== 생성형 AI

생성형 AI(Gen AI라고도 함) 는 사용자의 프롬프트 또는 요청에 따라 텍스트, 이미지, 비디오, 데이터 또는 기타 콘텐츠를 자율적으로 생성하는 AI의 범주입니다.

생성형 AI는 기존 콘텐츠의 패턴을 학습하고 그 학습을 기반으로 유사한 새로운 콘텐츠를 생성할 수 있는 딥러닝 모델에 의존합니다. 고객 서비스, 마케팅, 소프트웨어 개발, 연구 등 다양한 분야에서 활용되고 있으며, 빠르고 자동화된 콘텐츠 제작 및 증강을 통해 기업 워크플로우를 간소화할 수 있는 엄청난 잠재력을 제공합니다. 

생성형 AI는 이메일, 이미지, 비디오, 오디오 파일, 소셜 미디어 콘텐츠 등 다양한 데이터 소스를 처리하는 데 탁월합니다. 이 비정형 데이터는 모델 생성과 생성형 AI의 지속적인 교육을 위한 백본을 형성하므로 시간이 지나도 효율성을 유지할 수 있습니다. 이 비정형 데이터를 사용하면 챗봇을 통해 고객 서비스를 향상하고 보다 효과적인 이메일 라우팅을 촉진할 수 있습니다. 실제로 이는 사용자를 적절한 상담원과 연결하거나 사용자 가이드 및 FAQ로 안내하는 등 적절한 리소스로 사용자를 안내하는 것을 의미할 수 있습니다.

많은 논의가 이루어지고 있는 한계와 위험에도 불구하고, 많은 기업들이 생성형 AI를 활용하여 내부 워크플로우를 개선하고 제품과 서비스를 개선할 수 있는 방법을 신중하게 모색하고 있습니다. 이것은 새로운 개척지입니다. 법적 또는 윤리적 문제를 일으키지 않고 직장을 더욱 효율적으로 만드는 방법.

=== 자연어 처리 및 음성 인식

NLP는 컴퓨터 언어학(인간 언어의 규칙 기반 모델링)을 통계 및 머신 러닝 모델과 결합하여 컴퓨터와 디지털 디바이스가 텍스트와 음성을 인식 및 이해하고 생성할 수 있도록 합니다. NLP는 텍스트를 한 언어에서 다른 언어로 번역하고, 입력 또는 음성 명령에 응답하고, 음성을 기반으로 사용자를 인식하거나 인증할 수 있는 애플리케이션 및 장치를 지원합니다.  대량의 텍스트를 요약하고, 텍스트 또는 음성의 의도 또는 감정을 평가하고, 필요에 따라 텍스트, 그래픽 또는 기타 콘텐츠를 생성하는 데 도움이 됩니다.

NLP의 하위 집합은 컴퓨터 알고리즘을 기계 학습 및 딥 러닝 모델과 결합하는 통계적 NLP입니다. 이 접근 방식은 텍스트 및 음성 데이터의 요소를 자동으로 추출, 분류 및 레이블을 지정한 다음 해당 요소의 가능한 각 의미에 통계적 우도를 할당하는 데 도움이 됩니다. 오늘날 RNN을 기반으로 하는 딥 러닝 모델과 학습 기술을 통해 NLP 시스템은 작업하면서 "학습"하고 방대한 양의 원시적이고 구조화되지 않고 레이블이 지정되지 않은 텍스트 및 음성 데이터 세트에서 훨씬 더 정확한 의미를 추출할 수 있습니다.

자동 음성 인식(ASR), 컴퓨터 음성 인식 또는 음성-텍스트 변환으로도 알려진 음성 인식은 프로그램이 사람의 음성을 서면 형식으로 처리할 수 있도록 하는 기능입니다.

음성 인식은 일반적으로 음성 인식과 혼동되지만 음성 인식은 음성을 음성 형식에서 텍스트 형식으로 변환하는 데 중점을 두는 반면 음성 인식은 개별 사용자의 음성을 식별하려고 합니다.

////
https://www.ibm.com/kr-ko/topics/deep-learning
////