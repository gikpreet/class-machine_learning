= Artifical Intelligence(인공지능)의 역사

* 컴퓨터에서 음성 및 작성된 언어를 확인, 이해, 번역하고 데이터를 분석하여 추천하는 기능을 포함하여 다양한 고급 기능을 수행할 수 있게 하는 일련의 기술
* Alan Turing의 1950년에 쓴 논문 'Computing Machinery and Intelligence(계산 기계와 지능)'에서 기계가 사고할 수 있는지 여부를 고찰
** 인공 지능이라는 용어를 처음 만들어 이론적, 철학적 개념으로 제시
** 이 기술을 현실화한 튜링 머신은 폰 노이만에 의해 구현되어 현대 컴퓨터구조의 표준이 됨
* 워런 맥컬론(Warren MaCullonch)과 월터 피츠(Walter Pitts)는 인공 뉴런 모델사용하여 사람 뇌의 간단한 기능을 흉내낼 수 있음을 증명
** 코넬대 심리학자 프랭크 로센블레트(Frank Roselblank)에 의해 Perceptron이 개발됨
** 마빈 민스키(Marvin Minsky)와 세미무어 퍼펫(Semimure Pepert)는 Perceptron의 한계를 증명하여, 인공지능의 암흑기 도래
* 1970년 이후 실용적인 통계 기술에 집중
** 실험 계획법 빛 통계 분석 기술로 제조 품질/생산 효율 향상에 영향을 줄 수 있음을 보임
** 데이터 마이닝(Data mining)기술로, 빅데이터 기술의 근간이 됨
** 투자 대비 효용성의 한계로 시뮬레이션 등으로 연구 방향이 전환됨
* 2006년 이후 심층 신경망 기술로 컴퓨터공학의 주요 분야로 성장
** Deep-CNN(Convolution Neural Network: 합성곱신경망, 이미지 인식/분류 특화모델)은 이미지 인식 성능 평가 향상으로 딥러닝 기술이 재조명됨
** 2016년 구글 딥마인드를 필두로 CNN, RNN, GAN 기술이 상용화됨

---

== 인공지능의 태동과 암흑기

한편 미국의 신경외과의 워렌 맥컬록(Warren Mc Cullonch)과 논리학자 월터피츠(Walter Pitts)가 전기 스위치처럼 온, 오프 하는 기초기능의 인공신경을 그물망 형태로 연결하면 사람의 뇌에서 동작하는 아주 간단한 기능을 흉내 낼 수 있다는 것을 이론적으로 증명하였습니다. 또한 헵은 생물학적 신경망 내에서 반복적인 시그널이 발생할 때 신경세포들은 그 시그널을 기억하는 일종의 학습효과가 있음을 증명하였습니다.

1950년 영국수학자 앨런 튜링은 ‘계산 기계와 지능(Computing Machinery and Intelligence)’라는 논문에서 기계가 생각할 수 있는지 테스트하는 방법, 지능적 기계의 개발 가능성, 학습하는 기계 등에 대해 기술하였습니다. 이 기술을 현실화한 튜링머신은 존 폰 노이만 교수에게 직/간접적인 영향을 주어 현대 컴퓨터 구조의 표준이 되었으며. 세간에서는 이것을 인공지능 역사의 시작으로 보고 있습니다.

이를 계기로 대학원생인 Marvin Minsky와 Dean Edmonds는 최초의 신경망 기계인 SNARC를 구축했고, Frank Rosenblatt은 신경망의 초기 모델 중 하나인 Perceptron을 개발했으며, Joseph Weizenbaum은 1951년부터 1969년까지 Rogerian 심리치료사를 시뮬레이션한 최초의 챗봇 중 하나인 ELIZA를 개발했습니다.

마빈 민스키와 세이무어 페퍼트는 저서를 통해 퍼셉트론은 AND 또는 OR 같은 선형 분리가 가능한 문제는 가능하지만, XOR문제에는 적용할 수 없다는 것을 수학적 증명으로 발표했과, 1969년부터 1979년까지 Marvin Minsky는 신경망의 한계를 입증했습니다. 이에 따라 미국방부 DARPA는 AI 연구자금을 2천만달러를 전격 중단하기에 이르렀습니다.이로 인해 신경망 연구가 일시적으로 쇠퇴했습니다. 첫 번째 'AI 겨울'은 자금 부족과 하드웨어 및 컴퓨팅의 한계로 인해 발생했습니다.

== 통계/데이터 기반 인공지능과 두 번째 암흑기

1970년대 이후 대부분 기업은 R&D의 방향을 실용적인 통계기술에 집중하게 됩니다. 현대통계학은 1900년대 피셔/피어슨을 선두로 시작하여, 영국의 조지 박스, 일본의 다꾸치 같은 학자들의 노력으로 발전하게 됩니다. 이들은 실험계획법 및 통계 분석기술로 제조 품질/생산효율 향상에 영향을 줄 수 있음을 보였습니다. 이 개념은 데이터마이닝이라는 이름으로 산업에 비효율성을 해결하는 도구로 현재까지 사용되어왔고 빅데이터 기술의 근간이 되어 자리 잡게 되었습니다.

한동안 잠잠했던 인공지능 연구는 1980년대 산업계에 전문가 시스템이 도입되며 본격적으로 확산하게 됩니다. 전문가 시스템은 

1. 지식과 경험의 데이터베이스화 
2. 의사결정 추론엔진 
3. 사용자 인터페이스

로 구성되어있는데, 이 당시 추론엔진 기술은 베이즈(Bayes)기반 확률적 방법과, 또 다른 접근법으로 0과 1 사이에도 여러 가지 값을 가질 수 있는 퍼지(Fuzzy)이론을 통해 다중 값 논리방법을 이용하는 방법이 주로 활용되었습니다.

퍼지전문가 시스템은 1975년에 영국의 런던대학 에브라힘 맘다니 교수가 증기기관 제어 적용에 성공하여, 이때 적용된 맘다니 기법을 위시하여 퍼지 전문가 시스템이 한동안 인공지능을 대표하는 기술로 자리 잡게 되었습니다.

당시 미국의 500대 기업 절반이상이 전문가시스템을 사용했고 지속적인 투자를 한동안 받았습니다. 하지만 방대한 관리방안과 투자대비 효용성의 한계가 노출되어 인공지능의 연구는 약해지고, 1993년 미국부터 대부분 연구방향은 슈퍼컴퓨터와 시뮬레이션 분야로 연구방향을 전환하게 됩니다.

하지만 이런 인공지능의 암흑기에서도 리처드 밸벨만 등이 주창한 기계제어를 위한 강화학습(Reinforcement Learning), 조지 박스와 일본의 품질 연구가들이 주창한 실험계획법 및 통계적 공정(품질) 기법들이 산업 분야에 활용되어왔습니다. 반면 딥러닝의 기초모델인 역전파 등의 획기적인 AI 연구들이 발표는 되었지만, 컴퓨터 성능 및 제한적인 활용, 머신러닝 알고리즘으로 대체되는 등 여러 제한으로 인하여 세상에 주목 받지 못하고 사장되어 갔습니다. 

== 심층 신경망 기술로 인간의 인지능력을 모방

특히 Deep-CNN(Convolution Neural Network: 합성곱신경망, 이미지 인식/분류 특화모델)은 이미지 인식 성능 평가에서 2011년에는 26%인식 오류율을 보였으나, 2015년4년만에 3.5%로 개선하는 괄목할 성과를 보였습니다. 이를 기점으로 전문가들 사이에서 신경망 기반 인공지능(딥러닝) 기술이 재조명되게 됩니다.

일례로 이렇게 딥러닝의 가능성이 증명되자 2014년 구글은 딥마인드 테크놀로지 사(DeepMind Technologies: 영국 런던에서 설립되었으며 강화학습 특화된 회사)를 4억달러에 인수했습니다.

그 이후 2016년 알파고1.0 (16만 기보 지도학습기반 심층강화학습과 확률적 샘플링기반 의사결정)이 이세돌을 이기고. 2017년 2.0(비지도학습 소량데이터 기반 자가학습)으로 커제 및 탑클라스 바둑기사들에게 승리하면서, 인공지능(AI)기술이 일반인들에게도 확실히 인식되고, 완전히 재조명되는 계기가 되었습니다.

현재까지 실증화된 인공지능(AI)기술은 CNN, RNN(Recurrent Neural Network : 음성과 문자분야에 강한 신경망)입니다. 최근에는 2017년 이안 굿펠로우의 GAN(Generative Adversarial Nets: Image를 만들어내는 모델과 다양한 모델간에 서로 대립(Adversarial)하며 성능 개선하는 학습개념(낮은 수준의 사람처럼 글쓰기,노래하기 등이 가능)이 현재 인공지능(AI)를 이끌고 있습니다. 또한 실용성이 없어 보이던 추론(Reasoning) 연구 또한 조금씩 성과를 보이고 있으며, 이형의 정보학습을 새로운 문제를 효율적으로 해결하는 전이학습(transfer learning) 연구 역시 급속히 진행되고 있습니다. 이처럼 딥러닝의 등장 이후 인공지능은(AI) 빠른 발전을 보이있고, 이후에는 기술이 화두가 될지 전혀 예측할 수가 없을 정도로 급격하게 변화하고 있습니다.

우선 구글과 페이스북은 딥러닝을 활용한 얼굴 인식 기술에서 99.96%와 97.25%의 정확도를 확보 하였고, 아마존은 2014년 인공지능을 활용하여 로그인 시 물류창고에서 배송절차를 시작하는 결제예측배송 특허를 등록했습니다.

또한 영국 유니버시티 칼리지런던(UCL), 셰필드대, 미국 펜실베니아주립대의 공동 연구의 결과물로 만들어진 인공지능 판사는 79% 정확도로 재판의 결과를 예측 하였으며, IBM AI 로스는 파산관리변호사로 공식선임 되기도 하였습니다.

그리고 미국종양학회의 IBM왓슨의 대장암/직장암 진단 정확도는 이미 90%가 넘는 수준이며, 테슬라의 AutoPilot은 인간 개입을 배제한 자율주행이 가능한 수준에 이르렀습니다.

한편으로 B2B산업에서 인공지능 적용을 살펴 보면, GE사의 Brilliant Factory의 Predix는 다양한 기계학습, 딥러닝 기반 데이터분석기술로 가동중지를 예방하는 의사결정을 내리고, 최적의 생산을 유지하고 있습니다. 또한 지멘스(Siemens)의 스마트팩토리는 매일 5,000만건으로 제조공정의 75%를 자동으로 작업을 지시하며, 인력의 개입을 최소화 시키고 있습니다.
