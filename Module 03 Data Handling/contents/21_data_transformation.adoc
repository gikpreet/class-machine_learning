= 데이터 변환 (Data Transformation)

**데이터 변환(Data Transformation)**은 데이터 전처리 과정 중 하나로, 원본 데이터를 분석 및 모델링에 적합한 형태로 변환하는 과정입니다. 데이터 변환은 주로 데이터의 품질을 높이고, 분석이나 예측 모델에서 성능을 최적화하기 위해 수행됩니다. 데이터 변환은 여러 방법과 기술을 포함하며, 이는 데이터의 특성과 목적에 따라 달라집니다.

데이터 변환의 주요 목적은 모델의 성능을 높이고, 분석이 용이하도록 데이터를 준비하는 것입니다. 이를 위해 여러 변환 기법을 사용할 수 있으며, 데이터의 형식을 조정하거나, 새로운 특성을 생성하고, 값의 범위를 조정하는 등의 작업이 포함됩니다.

1. 형식 변환(Format Transformation) +
형식 변환은 데이터를 다른 형식으로 변환하는 과정입니다. 예를 들어, 날짜 형식을 일관되게 맞추거나, 범주형 데이터를 숫자형으로 변환하는 것이 이에 해당합니다.
* 날짜 형식 변환 +
예를 들어, "2024-12-23"과 같은 날짜 데이터를 일관된 형식으로 변환하거나, 년, 월, 일 등의 개별 특성으로 분리할 수 있습니다.
* 범주형 데이터 인코딩 +
범주형 데이터를 숫자형으로 변환하는 과정입니다. 예를 들어, "Male", "Female"을 각각 1, 0으로 변환할 수 있습니다. 이때 사용되는 기법은 **레이블 인코딩(Label Encoding)**이나 **원-핫 인코딩(One-Hot Encoding)**이 있습니다.
2. 스케일링(Scaling)
스케일링은 데이터의 값이 특정 범위나 분포를 따르도록 변환하는 과정입니다. 특히, 다양한 범위의 특성을 가진 데이터가 있을 때 모델 학습에 영향을 미칠 수 있기 때문에 스케일링은 중요합니다. 주요 스케일링 기법은 다음과 같습니다:
* 정규화(Normalization) +
데이터의 값을 특정 범위(주로 0과 1 사이)로 압축하는 방법입니다. 이는 **최소-최대 정규화(Min-Max Scaling)**를 사용하여 이루어집니다.
+
[source, python]
----
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(data)
----
* 표준화(Standardization): 데이터의 평균을 0, 표준편차를 1로 맞추는 방식입니다. 이는 Z-점수 표준화라고도 하며, 데이터의 분포를 보다 균일하게 만들어줍니다.
+
[source, python]
----
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
standardized_data = scaler.fit_transform(data)
----
+
3. 차원 축소(Dimensionality Reduction) +
차원 축소는 데이터의 특성(변수)의 수를 줄이는 과정입니다. 이는 데이터의 복잡성을 줄이고, 과적합(overfitting)을 방지하며, 모델의 계산 비용을 절감하는 데 도움이 됩니다. 주요 기법은 다음과 같습니다:
* 주성분 분석(PCA, Principal Component Analysis) +
PCA는 데이터를 몇 개의 주성분으로 변환하여 데이터의 차원을 축소합니다. 이때, 중요한 정보는 그대로 유지하면서, 불필요한 변수를 줄입니다.
+
[source, python]
----
from sklearn.decomposition import PCA
pca = PCA(n_components=2)  # 두 개의 주요 성분으로 차원 축소
reduced_data = pca.fit_transform(data)
----
* 선형 판별 분석(LDA, Linear Discriminant Analysis) +
LDA는 주로 분류 문제에서 사용되며, 각 클래스 간의 분리를 최대화하는 방향으로 차원을 축소합니다.

4. 데이터 인코딩(Data Encoding)
인코딩은 범주형 데이터를 수치형으로 변환하는 과정입니다. 이 과정은 기계 학습 모델이 범주형 데이터를 처리할 수 있도록 도와줍니다.

* 레이블 인코딩(Label Encoding) +
범주형 변수의 각 고유한 값을 정수로 변환하는 방법입니다. 예를 들어, "Red", "Blue", "Green"을 각각 0, 1, 2로 변환할 수 있습니다.
+
[source, python]
----
from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()
encoded_data = encoder.fit_transform(data)
----
* 원-핫 인코딩(One-Hot Encoding) +
각 범주를 이진 벡터로 변환하여, 범주가 가질 수 있는 값 중 하나를 1로, 나머지는 0으로 표시하는 방법입니다. 예를 들어, "Red", "Blue", "Green"을 3개의 열로 변환하여 각 값을 나타냅니다.
+
[source, python]
----
from sklearn.preprocessing import OneHotEncoder
encoder = OneHotEncoder()
encoded_data = encoder.fit_transform(data).toarray()
----
[source, python]
* 목표 인코딩(Target Encoding) +
범주형 변수에 대해 각 범주를 그 범주의 타겟 평균 값으로 인코딩하는 방법입니다. 주로 카테고리형 특성을 가진 데이터에서 사용됩니다.

5. 로그 변환(Log Transformation) +
로그 변환은 데이터의 분포를 변경하는 방법으로, 특히 비정규 분포나 긴 꼬리 분포를 가지는 데이터에서 사용됩니다. 로그 변환을 통해 데이터의 왜곡(skew)을 줄이고, 모델 학습을 더 쉽게 만들 수 있습니다.
+
예를 들어, 매우 큰 값이 있는 변수에서 로그 변환을 수행하면 값의 범위가 좁아지고 분포가 더 정상적으로 변할 수 있습니다.
+
[source, python]
----
import numpy as np
log_transformed_data = np.log1p(data)  # np.log1p는 0에 가까운 값을 처리할 때 유용합니다
----

6. 결측값 처리(Missing Value Imputation)
결측값 처리는 데이터에 결측값이 있을 때 이를 처리하는 방법입니다. 결측값을 처리하지 않으면 모델이 제대로 학습되지 않거나 예측 결과에 오류가 발생할 수 있습니다. 결측값 처리 방법은 다음과 같습니다:
+
* 평균/중앙값/최빈값 대체 +
수치형 데이터는 평균 또는 중앙값으로, 범주형 데이터는 최빈값으로 결측값을 대체할 수 있습니다.
+
[source, python]
----
from sklearn.impute import SimpleImputer
imputer = SimpleImputer(strategy='mean')  # 평균으로 대체
imputed_data = imputer.fit_transform(data)
----
* 예측 모델을 통한 대체 +
더 복잡한 방법으로, 결측값을 예측하는 모델을 훈련시켜 결측값을 대체하는 방법도 있습니다.

7. 데이터 결합(Data Merging) +
여러 데이터셋을 결합하는 과정입니다. 예를 들어, 여러 데이터 소스에서 얻은 정보를 하나의 테이블로 결합할 수 있습니다. 데이터 결합은 수평 결합(horizontal join) 또는 수직 결합(vertical join) 형태로 이루어질 수 있습니다.
+
* 수평 결합 +
공통된 키를 기준으로 여러 데이터를 옆으로 결합하는 방식입니다.
+
[source, python]
----
merged_data = pd.merge(df1, df2, on='common_column')
----
+
* 수직 결합 +
동일한 특성을 가진 데이터를 아래로 결합하는 방식입니다.
+
[source, python]
----
concatenated_data = pd.concat([df1, df2], axis=0)
----
+
8. 피벗 및 집계(Pivot and Aggregation) +
피벗(pivot)은 데이터를 요약하고, 특정 기준에 따라 데이터를 변환하는 과정입니다. 이를 통해 데이터를 더 쉽게 분석하고, 특정 그룹별 집계를 생성할 수 있습니다.

* 피벗 테이블 +
데이터를 특정 기준으로 그룹화하여 요약하는 테이블을 생성할 수 있습니다.
+
[source, python]
----
pivoted_data = df.pivot_table(values='sales', index='date', columns='region', aggfunc='sum')
----

데이터 변환은 데이터를 모델링에 적합한 형식으로 변환하고, 데이터를 분석하기 쉬운 형태로 만드는 중요한 과정입니다. 데이터의 품질을 높이고, 분석 및 모델링을 최적화하기 위한 다양한 기법을 사용할 수 있습니다. 데이터 변환을 잘 수행하면 더 정확하고 효과적인 예측을 할 수 있으며, 데이터 분석의 전반적인 성능을 향상시킬 수 있습니다.