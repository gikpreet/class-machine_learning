= 특성 공학의 단계

특성 공학은 머신 러닝 모델을 개선하기 위해 데이터를 처리하고 변환하는 과정입니다. 이 과정에서 데이터에서 중요한 특성(Feature)을 추출하고, 이를 모델이 잘 학습할 수 있는 형식으로 변환하는 작업을 포함합니다. 

== 문제 정의 및 목표 설정

특성 공학의 첫 단계는 모델이 해결하려는 문제를 정확히 이해하는 것입니다. 목표를 설정하고 데이터에서 추출해야 할 특성을 정의합니다. 예를 들면, 분류 문제인지 회귀 문제인지를 파악하고, 목표 변수와 그에 영향을 미칠 수 있는 특성을 고려해야 합니다.

== 데이터 수집 및 탐색

데이터 수집은 분석할 데이터를 모은 후, 특성 공학을 수행하는데 필요한 데이터를 선별하는 과정입니다. EDA(Exploratory Data Analysis - 탐색적 데이터 분석)을 통해 데이터의 분포, 상관 관계, 결측치 등을 파악하여 데이터를 깊이 이해합니다.

다양한 통계적 분석, 시각화를 통해 데이터를 탐색하고 문제의 특성을 파악하며, 결측치가 있는 데이터를 처리합니다. 결측치가 있는 데이터를 처리해야 하며, 결측치를 제거하거나 평균, 중앙값, 최빈값으로 대체하거나 예측 모델을 사용해 결측값을 채우는 등의 작업이 수반됩니다.

== 특성 생성 및 변환

* 특성 생성(Feature Creation) +
기존 데이터에서 새로운 특성을 생성하는 단계입니다. 예를 들어 날짜에서 연도, 월, 요일 등을 추출하거나 텍스트 데이터를 숫자형 특성으로 변환하는 등의 작업을 할 수 있습니다.
* 특성 변환(Feature Transormation) +
특정 특성을 모델에 맞게 변환하는 작업입니다. 로그 변환, 표준화, 정규화등을 사용하여 데이터의 분포를 모델에 적합하게 만들 수 있습니다.
* 범주형 변수 처리 +
범주형 변수는 One-hot encoding이나 label encoding을 통해 수치형 변수로 변환합니다.

== 차원 축소

특성이 너무 많은 경우, 모델이 복잡해져 과적합(overfitting)이나 계산 비용이 커질 수 있습니다. PCA(주성분 분석)이나 LDA(선형 판별 분석)를 사용해 데이터의 차원을 줄이는 작업을 진행합니다.

== 특성 선택(Feature Selection)

모델의 학습에 중요한 특성만 남기고, 불필요한 특성을 제거하는 과정입니다. 이는 과적합을 방지하고 모델의 해석성을 높이며, 학습 시간을 단축시킬 수 있습니다.

주로 상관 계수 분석, 선택적 알고리즘(L1 정규화 처리, 트리 기반 알고리즘 등), 임포턴스 평가등을 사용해 중요한 특성을 선택합니다.

== 모델 학습 및 평가

특성 공학을 통해 준비된 데이터를 바탕으로 머신 러닝 모델을 학습시키고 교차 검증 등을 통해 모델 성능을 평가합니다. 잘 수행된 특성 공학은 예측이 정확한 모델을 만들 수 있도록 합니다.

== 모델 개선

모델 성능을 평가하고, 더 나은 결과를 얻기 위해 특성을 추가하거나 변환하여 모델을 개선할 수 있습니다. 모델 튜닝(하이퍼 파라미터 튜닝)을 통해 성능을 최적화 합니다.